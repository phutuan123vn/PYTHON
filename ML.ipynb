{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0,'HW1_ML/')\n",
    "from util import get_vehicle_data\n",
    "import time\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading vehicle data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vehicles.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PhuTuan\\Documents\\VSC\\PYTHON\\ML.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 215>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m2018\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=217'>218</a>\u001b[0m \u001b[39m# Load data from file\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m \u001b[39m# Make sure that vehicles.dat is in data/\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=219'>220</a>\u001b[0m train_x, train_y, test_x, test_y \u001b[39m=\u001b[39m get_vehicle_data()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=220'>221</a>\u001b[0m num_train \u001b[39m=\u001b[39m train_x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/PhuTuan/Documents/VSC/PYTHON/ML.ipynb#W5sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m num_test \u001b[39m=\u001b[39m test_x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\PhuTuan\\Documents\\VSC\\PYTHON\\HW1_ML\\util.py:74\u001b[0m, in \u001b[0;36mget_vehicle_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mLoad vehicle data and return it as a list: [train_x, train_y, test_x, test_y]\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mReading vehicle data...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m train_x, train_y, test_x, test_y \u001b[39m=\u001b[39m load_list(\u001b[39m'\u001b[39;49m\u001b[39mdata/vehicles.dat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     75\u001b[0m train_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(train_x, (\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m     76\u001b[0m test_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(test_x, (\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\PhuTuan\\Documents\\VSC\\PYTHON\\HW1_ML\\util.py:39\u001b[0m, in \u001b[0;36mload_list\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m end_of_file \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     38\u001b[0m list_obj \u001b[39m=\u001b[39m [] \n\u001b[1;32m---> 39\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(file_name, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     40\u001b[0m python_version \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mversion_info[\u001b[39m0\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[39mwhile\u001b[39;00m (\u001b[39mnot\u001b[39;00m end_of_file):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vehicles.dat'"
     ]
    }
   ],
   "source": [
    "class LogisticClassifier(object):\n",
    "    def __init__(self, w_shape):\n",
    "        \"\"\"__init__\n",
    "\n",
    "        :param w_shape: create w with shape w_shape using normal distribution\n",
    "        \"\"\"\n",
    "\n",
    "        mean = 0\n",
    "        std = 1\n",
    "        self.w = np.random.normal(0, np.sqrt(2./np.sum(w_shape)), w_shape)\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        \"\"\"feed_forward\n",
    "        This function compute the output of your logistic classification model\n",
    "\n",
    "        :param x: input\n",
    "\n",
    "        :return result: feed forward result (after sigmoid) \n",
    "        \"\"\"\n",
    "        # [TODO 1.5]\n",
    "        # Compute feedforward result\n",
    "\n",
    "        result = 0\n",
    "        return result\n",
    "\n",
    "    def compute_loss(self, y, y_hat):\n",
    "        \"\"\"compute_loss\n",
    "        Compute the loss using y (label) and y_hat (predicted class)\n",
    "\n",
    "        :param y:  the label, the actual class of the samples\n",
    "        :param y_hat: the propabilitis that the given samples belong to class 1\n",
    "\n",
    "        :return loss: a single value\n",
    "        \"\"\"\n",
    "        # [TODO 1.6]\n",
    "        # Compute loss value (a single number)\n",
    "\n",
    "        loss = 0\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "\n",
    "    def get_grad(self, x, y, y_hat):\n",
    "        \"\"\"get_grad\n",
    "        Compute and return the gradient of w\n",
    "\n",
    "        :param loss: computed loss between y_hat and y in the train dataset\n",
    "        :param y_hat: predicted y\n",
    "\n",
    "        :return w_grad: has the same shape as self.w\n",
    "        \"\"\"\n",
    "        # [TODO 1.7]\n",
    "        # Compute the gradient matrix of w, it has the same size of w\n",
    "\n",
    "        w_grad = 0\n",
    "        return w_grad\n",
    "\n",
    "    def update_weight(self, grad, learning_rate):\n",
    "        \"\"\"update_weight\n",
    "        Update w using the computed gradient\n",
    "\n",
    "        :param grad: gradient computed from the loss\n",
    "        :param learning_rate: float, learning rate\n",
    "        \"\"\"\n",
    "        # [TODO 1.8]\n",
    "        # Update w using SGD\n",
    "\n",
    "        self.w = 0\n",
    "\n",
    "    def update_weight_momentum(self, grad, learning_rate, momentum, momentum_rate):\n",
    "        \"\"\"update_weight with momentum\n",
    "        Update w using the algorithm with momnetum\n",
    "\n",
    "        :param grad: gradient computed from the loss\n",
    "        :param learning_rate: float, learning rate\n",
    "        :param momentum: the array storing momentum for training w, should have the same shape as w\n",
    "        :param momentum_rate: float, how much momentum to reuse after each loop (denoted as gamma in the document)\n",
    "        \"\"\"\n",
    "        # [TODO 1.9]\n",
    "        # Update w using SGD with momentum\n",
    "\n",
    "        self.w = 0\n",
    "\n",
    "\n",
    "def plot_loss(all_loss):\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.plot(all_loss)\n",
    "\n",
    "\n",
    "def normalize_per_pixel(train_x, test_x):\n",
    "    \"\"\"normalize_per_pixel\n",
    "    This function computes train mean and standard deviation on each pixel then applying data scaling on train_x and test_x using these computed values\n",
    "\n",
    "    :param train_x: train images, shape=(num_train, image_height, image_width)\n",
    "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
    "    \"\"\"\n",
    "    # [TODO 1.1]\n",
    "    # train_mean and train_std should have the shape of (1, image_height, image_width)\n",
    "    # train_x = ...\n",
    "    # test_x = ...\n",
    "\n",
    "    train_x = 0\n",
    "    test_x = 0\n",
    "\n",
    "    return train_x, test_x\n",
    "\n",
    "\n",
    "def normalize_all_pixel(train_x, test_x):\n",
    "    \"\"\"normalize_all_pixel\n",
    "    This function computes train mean and standard deviation on all pixels then applying data scaling on train_x and test_x using these computed values\n",
    "\n",
    "    :param train_x: train images, shape=(num_train, image_height, image_width)\n",
    "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
    "    \"\"\"\n",
    "    # [TODO 1.2]\n",
    "    # train_mean and train_std should have the shape of (1, image_height, image_width)\n",
    "    train_x = 0\n",
    "    test_x = 0\n",
    "\n",
    "    return train_x, test_x\n",
    "\n",
    "\n",
    "def reshape2D(tensor):\n",
    "    \"\"\"reshape_2D\n",
    "    Reshape our 3D tensors to 2D. A 3D tensor of shape (num_samples, image_height, image_width) must be reshaped into (num_samples, image_height*image_width)\n",
    "    \"\"\"\n",
    "    # [TODO 1.3]\n",
    "    tensor = 0\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def add_one(x):\n",
    "    \"\"\"add_one\n",
    "\n",
    "    This function add ones as an additional feature for x\n",
    "    :param x: input data\n",
    "    \"\"\"\n",
    "    # [TODO 1.4]\n",
    "    x = 0\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def test(y_hat, test_y):\n",
    "    \"\"\"test\n",
    "    Compute precision, recall and F1-score based on predicted test values\n",
    "\n",
    "    :param y_hat: predicted values, output of classifier.feed_forward\n",
    "    :param test_y: test labels\n",
    "    \"\"\"\n",
    "\n",
    "    # [TODO 1.10]\n",
    "    # Compute test scores using test_y and y_hat\n",
    "    #precision = TP/(TP+FP)\n",
    "    precision = 0\n",
    "    #recall = TP/P\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    print(\"Precision: %.3f\" % precision)\n",
    "    print(\"Recall: %.3f\" % recall)\n",
    "    print(\"F1-score: %.3f\" % f1)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def generate_unit_testcase(train_x, train_y):\n",
    "    train_x = train_x[0:5, :, :]\n",
    "    train_y = train_y[0:5, :]\n",
    "\n",
    "    testcase = {}\n",
    "    testcase['output'] = []\n",
    "\n",
    "    train_x_norm1, _ = normalize_per_pixel(train_x, train_x)\n",
    "    train_x_norm2, _ = normalize_all_pixel(train_x, train_x)\n",
    "    train_x = train_x_norm2\n",
    "\n",
    "    testcase['train_x_norm1'] = train_x_norm1\n",
    "    testcase['train_x_norm2'] = train_x_norm2\n",
    "\n",
    "    train_x = reshape2D(train_x)\n",
    "    testcase['train_x2D'] = train_x\n",
    "\n",
    "    train_x = add_one(train_x)\n",
    "    testcase['train_x1'] = train_x\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    momentum_rate = 0.9\n",
    "\n",
    "    for i in range(10):\n",
    "        test_dict = {}\n",
    "        classifier = LogisticClassifier((train_x.shape[1], 1))\n",
    "        test_dict['w'] = classifier.w\n",
    "\n",
    "        y_hat = classifier.feed_forward(train_x)\n",
    "        loss = classifier.compute_loss(train_y, y_hat)\n",
    "        grad = classifier.get_grad(train_x, train_y, y_hat)\n",
    "        classifier.update_weight(grad, 0.001)\n",
    "        test_dict['w_1'] = classifier.w\n",
    "\n",
    "        momentum = np.ones_like(grad)\n",
    "        classifier.update_weight_momentum(\n",
    "            grad, learning_rate, momentum, momentum_rate)\n",
    "        test_dict['w_2'] = classifier.w\n",
    "\n",
    "        test_dict['y_hat'] = y_hat\n",
    "        test_dict['loss'] = loss\n",
    "        test_dict['grad'] = grad\n",
    "\n",
    "        testcase['output'].append(test_dict)\n",
    "\n",
    "    np.save('./data/unittest', testcase)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(2018)\n",
    "\n",
    "    # Load data from file\n",
    "    # Make sure that vehicles.dat is in data/\n",
    "    train_x, train_y, test_x, test_y = get_vehicle_data()\n",
    "    num_train = train_x.shape[0]\n",
    "    num_test = test_x.shape[0]\n",
    "\n",
    "    #generate_unit_testcase(train_x.copy(), train_y.copy())\n",
    "\n",
    "    # Normalize our data: choose one of the two methods before training\n",
    "    #train_x, test_x = normalize_all_pixel(train_x, test_x)\n",
    "    train_x, test_x = normalize_per_pixel(train_x, test_x)\n",
    "\n",
    "    # Reshape our data\n",
    "    # train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
    "    # test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
    "    train_x = reshape2D(train_x)\n",
    "    test_x = reshape2D(test_x)\n",
    "\n",
    "    # Pad 1 as the last feature of train_x and test_x\n",
    "    train_x = add_one(train_x)\n",
    "    test_x = add_one(test_x)\n",
    "\n",
    "    # Create classifier\n",
    "    num_feature = train_x.shape[1]\n",
    "    bin_classifier = LogisticClassifier((num_feature, 1))\n",
    "    momentum = np.zeros_like(bin_classifier.w)\n",
    "\n",
    "    # Define hyper-parameters and train-related parameters\n",
    "    num_epoch = 1000\n",
    "    learning_rate = 0.01\n",
    "    momentum_rate = 0.9\n",
    "    epochs_to_draw = 100\n",
    "    all_loss = []\n",
    "    plt.ion()\n",
    "    tic = time.clock()\n",
    "    for e in range(num_epoch):\n",
    "        tic = time.clock()\n",
    "        y_hat = bin_classifier.feed_forward(train_x)\n",
    "        loss = bin_classifier.compute_loss(train_y, y_hat)\n",
    "        grad = bin_classifier.get_grad(train_x, train_y, y_hat)\n",
    "\n",
    "        # Updating weight: choose either normal SGD or SGD with momentum\n",
    "        #bin_classifier.update_weight(grad, learning_rate)\n",
    "        bin_classifier.update_weight_momentum(\n",
    "            grad, learning_rate, momentum, momentum_rate)\n",
    "\n",
    "        all_loss.append(loss)\n",
    "\n",
    "        if (e % epochs_to_draw == epochs_to_draw-1):\n",
    "            plot_loss(all_loss)\n",
    "            plt.show()\n",
    "            plt.pause(0.1)\n",
    "            print(\"Epoch %d: loss is %.5f\" % (e+1, loss))\n",
    "        toc = time.clock()\n",
    "        print(toc-tic)\n",
    "\n",
    "    y_hat = bin_classifier.feed_forward(test_x)\n",
    "    test(y_hat, test_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77bd7aacb429543d1defe97202d84abe615362f6ac5646d480f574bc453493ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
